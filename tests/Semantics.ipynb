{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dualneuron.screening.sets import ImagenetImages\n",
    "from dualneuron.screening.utils import load_poles\n",
    "from dualneuron.dream.axis import semantic_axis\n",
    "import dualneuron\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "data_dir = os.getenv(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "package_dir = Path(dualneuron.__file__).parent\n",
    "mask_path = package_dir / \"twins\" / \"V4ColorTaskDriven\" / \"mask.npy\"\n",
    "mask = np.load(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23215c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = ImagenetImages(\n",
    "    data_dir=data_dir + \"datasets\",\n",
    "    token=token,\n",
    "    split=\"train\",\n",
    "    use_center_crop=True,\n",
    "    use_resize_output=True,\n",
    "    use_grayscale=False,\n",
    "    use_normalize=False,\n",
    "    use_mask=True,\n",
    "    use_norm=True,\n",
    "    use_clip=True,\n",
    "    mask=mask,\n",
    "    num_channels=3,\n",
    "    output_size=(224, 224),\n",
    "    crop_size=236,\n",
    "    bg_value=0.0,\n",
    "    clip_min=0.0,\n",
    "    clip_max=1.0,\n",
    "    norm=80.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11329083",
   "metadata": {},
   "outputs": [],
   "source": [
    "lais, mais = load_poles(\n",
    "    neuron_id=6,\n",
    "    dset=dset,\n",
    "    idx_dir=data_dir + 'v4_imagenet_ordered_indices',\n",
    "    k=10,\n",
    "    pole='both'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef598910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dreamsim import dreamsim\n",
    "\n",
    "dreamsim_model, _ = dreamsim(\n",
    "    pretrained=True, \n",
    "    device='cuda',\n",
    "    dreamsim_type='dinov2_vitb14',\n",
    "    cache_dir=data_dir + 'dreamsim_models'\n",
    ")\n",
    "\n",
    "axis = semantic_axis(mais, lais, dreamsim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 10, figsize=(20, 4))\n",
    "\n",
    "for i in range(10):\n",
    "    axs[0, i].imshow(lais[i].permute(1, 2, 0))\n",
    "    axs[0, i].axis('off')\n",
    "    axs[0, i].set_title(f'LAI {i+1}')\n",
    "\n",
    "    axs[1, i].imshow(mais[i].permute(1, 2, 0))\n",
    "    axs[1, i].axis('off')\n",
    "    axs[1, i].set_title(f'MAI {i+1}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dualneuron.twins.nets import V4ColorTaskDriven\n",
    "from dualneuron.twins.activations import WrapLayer, model_summary\n",
    "\n",
    "from dualneuron.synthesis.ascend import fourier_ascending\n",
    "from dualneuron.synthesis.visualize import (\n",
    "    blend, plot_group, plot_poles, sequence_animation\n",
    ")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1816db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function = V4ColorTaskDriven(centered=True, ensemble=False).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c94172",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = WrapLayer(model=function, layer=function)\n",
    "shape = layer(torch.randn(1, 3, 100, 100).to(device)).shape\n",
    "units = np.random.choice(shape[1], size=30, replace=False)\n",
    "\n",
    "lr = 1.0\n",
    "nb_crops = 16\n",
    "norm = 40.0\n",
    "\n",
    "act_weight = -1.0\n",
    "sim_weights = [-2.0, -1.0, 1.0, 2.0]\n",
    "results = []\n",
    "\n",
    "for sim_weight in sim_weights:\n",
    "    result = fourier_ascending(\n",
    "        lambda x: act_weight * torch.mean(layer(x)[:, 35]),\n",
    "        magnitude_path='natural_rgb.npy',\n",
    "        image_size=None,\n",
    "        init_image=None,\n",
    "        total_steps=128,\n",
    "        learning_rate=lr,\n",
    "        lr_schedule=True,\n",
    "        noise=0.0,\n",
    "        values_range=(-2.0, 2.0),\n",
    "        range_fn='sigmoid',\n",
    "        nb_crops=nb_crops,\n",
    "        box_size=(1.0, 1.0),\n",
    "        target_norm=norm,\n",
    "        tv_weight=0.0,\n",
    "        jitter_std=0.2,\n",
    "        oversample=1, \n",
    "        reflect_pad_frac=0.2,\n",
    "        simulation_function=lambda x: dreamsim_model.embed(x),\n",
    "        simulation_axis=None, \n",
    "        simulation_weight=sim_weight,\n",
    "        device='cuda',\n",
    "        verbose=True,\n",
    "        save_all_steps=True,\n",
    "    )\n",
    "    results.append(result)\n",
    "    \n",
    "layer.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "poles = []\n",
    "\n",
    "for result in results:\n",
    "    image = result['image'][-1]\n",
    "    alpha = result['alpha'][-1]\n",
    "    pole = blend(image, alpha, imagecut=0.0, alphacut=90.0, boost=1.2)\n",
    "    poles.append(pole)\n",
    "\n",
    "plot_group(poles, cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = []\n",
    "\n",
    "for img, alp in zip(results[0]['image'], results[0]['alpha']):\n",
    "    pole = blend(img, alp, imagecut=0.0, alphacut=90.0, boost=1.2)\n",
    "    sequence.append(pole)\n",
    "\n",
    "sequence_animation(\n",
    "    sequence, \n",
    "    np.array(result['activation'])*10,\n",
    "    savename=None, \n",
    "    dpi=50,\n",
    "    interval=50,\n",
    "    title=\"Optimization Progress\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358799a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
