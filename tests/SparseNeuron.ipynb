{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfec53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "\n",
    "from dualneuron.screening.sets import ImagenetImages, RenderedImages\n",
    "from dualneuron.screening.run import activations\n",
    "\n",
    "from pathlib import Path\n",
    "import dualneuron\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "data_dir = os.getenv(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22affa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(data_dir + \"dryad/v4_imagenet_ordered_responses.npz\")\n",
    "indices = np.load(data_dir + \"dryad/v4_imagenet_ordered_indices.npz\")\n",
    "\n",
    "model_name = \"V4ColorTaskDriven\"\n",
    "package_dir = Path(dualneuron.__file__).parent\n",
    "mask_path = package_dir / \"twins\" / model_name / \"mask.npy\"\n",
    "mask = np.load(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "skewness = {}\n",
    "\n",
    "for key in tqdm(data.keys()):\n",
    "    activations = data[key]\n",
    "    skew = stats.skew(activations)\n",
    "    skewness[key] = skew\n",
    "\n",
    "sorted_neurons = sorted(\n",
    "    skewness.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"Neurons ordered from most sparse to least sparse:\")\n",
    "print(\"-\" * 50)\n",
    "for neuron_id, skew in sorted_neurons[:10]:  # Show top 10\n",
    "    print(f\"Neuron: {neuron_id}, Skewness: {skew:.4f}\")\n",
    "\n",
    "ordered_neurons = [neuron_id for neuron_id, _ in sorted_neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "highpoles = {}\n",
    "num_imgs = 10\n",
    "\n",
    "for key in tqdm(ordered_neurons):\n",
    "    highpoles[key] = indices[key][-num_imgs:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = ImagenetImages(\n",
    "    data_dir=data_dir + \"datasets\",\n",
    "    token=token,\n",
    "    split='train',\n",
    "    use_center_crop=True,\n",
    "    use_resize_output=True,\n",
    "    use_grayscale=False,\n",
    "    use_normalize=False,\n",
    "    use_mask=True,\n",
    "    use_norm=False,\n",
    "    mask=mask,\n",
    "    num_channels=3,\n",
    "    output_size=(224, 224),\n",
    "    crop_size=236,\n",
    "    bg_value=0.45,\n",
    "    norm=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "highpole_images = {}\n",
    "\n",
    "for key in tqdm(highpoles.keys()):\n",
    "    image_indices = highpoles[key]\n",
    "    images = []\n",
    "    for idx in image_indices:\n",
    "        img, _ = dset[idx]\n",
    "        images.append(img.permute(1, 2, 0))\n",
    "\n",
    "    highpole_images[key] = np.stack(images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = 40\n",
    "fig, axes = plt.subplots(num_imgs, tail, figsize=(0.99 * tail, num_imgs))\n",
    "\n",
    "for i, neuron_id in enumerate(ordered_neurons[:tail]):\n",
    "    images = highpole_images[neuron_id]\n",
    "    skew = skewness[neuron_id]\n",
    "    act = data[neuron_id][-1]\n",
    "\n",
    "    for j, img in enumerate(images[:num_imgs]):\n",
    "        if j == 0:\n",
    "            axes[j, i].set_title(f\"{skew:.2f} \\n {act:.2f}\", fontsize=8)\n",
    "        axes[j, i].imshow(img)\n",
    "        axes[j, i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(num_imgs, tail, figsize=(0.99 * tail, num_imgs))\n",
    "\n",
    "for i, neuron_id in enumerate(ordered_neurons[-tail:]):\n",
    "    images = highpole_images[neuron_id]\n",
    "    skew = skewness[neuron_id]\n",
    "    act = data[neuron_id][-1]\n",
    "\n",
    "    for j, img in enumerate(images[:num_imgs]):\n",
    "        if j == 0:\n",
    "            axes[j, i].set_title(f\"{skew:.2f} \\n {act:.2f}\", fontsize=8)\n",
    "        axes[j, i].imshow(img)\n",
    "        axes[j, i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23291fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
