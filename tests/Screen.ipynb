{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73088a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "\n",
    "from dualneuron.screening.sets import ImagenetImages\n",
    "from dualneuron.screening.run import screen_activations\n",
    "\n",
    "from dualneuron.screening.visualize import (\n",
    "    plot_population_statistics,\n",
    "    plot_neuron_activation,\n",
    "    plot_neuron_poles,\n",
    ")\n",
    "\n",
    "from dualneuron.screening.utils import compute_population_statistics\n",
    "from dualneuron.twins.nets import model_summary\n",
    "\n",
    "from pathlib import Path\n",
    "import dualneuron\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "data_dir = os.getenv(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = 'resnet50'\n",
    "model, hooks = model_summary(architecture, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = 'resnet50'\n",
    "layer = 'layer3.1.relu'\n",
    "dataset = \"imagenet\"\n",
    "\n",
    "if False:\n",
    "    screen_activations(\n",
    "        data_dir + \"datasets\",\n",
    "        output_dir=data_dir + \"dryad\",\n",
    "        token=token,\n",
    "        split='test',\n",
    "        dataset=dataset,\n",
    "        model=architecture,\n",
    "        layer=layer,\n",
    "        location='center',\n",
    "        ensemble=True,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        device=\"cuda\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47042dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"V4ColorTaskDriven\"\n",
    "package_dir = Path(dualneuron.__file__).parent\n",
    "mask_path = package_dir / \"twins\" / model_name / \"mask.npy\"\n",
    "mask = np.load(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = ImagenetImages(\n",
    "    data_dir=data_dir + \"datasets\",\n",
    "    token=token,\n",
    "    split='test',\n",
    "    use_center_crop=True,\n",
    "    use_resize_output=True,\n",
    "    use_grayscale=False,\n",
    "    use_normalize=False,\n",
    "    use_mask=True,\n",
    "    use_norm=False,\n",
    "    use_clip=False,\n",
    "    mask=mask,\n",
    "    num_channels=3,\n",
    "    output_size=(224, 224),\n",
    "    crop_size=236,\n",
    "    bg_value=0.0,\n",
    "    norm=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ff81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_dir = data_dir + f\"dryad/{architecture}_{layer}_{dataset}_ordered_indices\"\n",
    "resp_dir = data_dir + f\"dryad/{architecture}_{layer}_{dataset}_ordered_responses\"\n",
    "num_neurons = len([f for f in os.listdir(resp_dir) if f.endswith('.npy')])\n",
    "print(f\"Number of .npy files in resp_dir: {num_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d49c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_stats, active_neurons = compute_population_statistics(resp_dir, sort_by='gini')\n",
    "plot_population_statistics(response_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e88b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = active_neurons.index(23)\n",
    "plot_neuron_activation(active_neurons[unit], resp_dir, response_stats)\n",
    "plot_neuron_poles(active_neurons[unit], dset, resp_dir, idx_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f675eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_images_animation(\n",
    "    neuron_id,\n",
    "    dset,\n",
    "    resp_dir,\n",
    "    idx_dir,\n",
    "    num_samples=100,\n",
    "    savename='neuron_animation.mp4',\n",
    "    fps=5,\n",
    "    figsize=(10, 5),\n",
    "    dpi=100,\n",
    "    vmin=None,\n",
    "    vmax=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create animation showing adaptively sampled images with their position on the activation curve.\n",
    "    Uses OpenCV for fast video generation.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    from io import BytesIO\n",
    "    import torch\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Use non-interactive backend\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    # Load ALREADY SORTED responses and indices\n",
    "    sorted_responses = np.load(os.path.join(resp_dir, f\"{neuron_id}.npy\"))\n",
    "    sorted_dataset_indices = np.load(os.path.join(idx_dir, f\"{neuron_id}.npy\"))\n",
    "    \n",
    "    # Adaptive sampling\n",
    "    rng = np.random.default_rng(seed=num_samples)\n",
    "    diffs = np.abs(np.diff(sorted_responses))\n",
    "    probs = diffs / np.sum(diffs)\n",
    "    \n",
    "    sampled_transitions = rng.choice(\n",
    "        len(probs),\n",
    "        num_samples,\n",
    "        p=probs,\n",
    "        replace=False\n",
    "    )\n",
    "    sampled_positions = np.sort(sampled_transitions + 1)\n",
    "    sampled_dataset_idx = sorted_dataset_indices[sampled_positions]\n",
    "    sampled_activations = sorted_responses[sampled_positions]\n",
    "    \n",
    "    print(f\"Loading {num_samples} images...\")\n",
    "    # Pre-load and process all images\n",
    "    images = []\n",
    "    for idx in sampled_dataset_idx:\n",
    "        img, _ = dset[idx]\n",
    "        \n",
    "        if torch.is_tensor(img):\n",
    "            img = img.cpu().numpy()\n",
    "        \n",
    "        if img.ndim == 3:\n",
    "            if img.shape[0] in [1, 3]:\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "            if img.shape[2] == 1:\n",
    "                img = img.squeeze(2)\n",
    "        \n",
    "        # Normalize\n",
    "        if vmin is not None and vmax is not None:\n",
    "            img = np.clip(img, vmin, vmax)\n",
    "            img = (img - vmin) / (vmax - vmin)\n",
    "        else:\n",
    "            img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "        \n",
    "        images.append(img)\n",
    "    \n",
    "    print(\"Generating frames...\")\n",
    "    # Generate each frame\n",
    "    frames = []\n",
    "    \n",
    "    for frame_idx in range(num_samples):\n",
    "        # Create figure for this frame\n",
    "        fig = plt.figure(figsize=figsize, dpi=dpi, facecolor='black')\n",
    "        \n",
    "        # Image on left\n",
    "        ax_img = fig.add_subplot(1, 2, 1, aspect='equal')\n",
    "        ax_img.set_axis_off()\n",
    "        ax_img.set_facecolor('black')\n",
    "        \n",
    "        ax_img.imshow(images[frame_idx], cmap='gray', vmin=0, vmax=1)\n",
    "        \n",
    "        current_activation = sampled_activations[frame_idx]\n",
    "        current_position = sampled_positions[frame_idx]\n",
    "        value_color = '#00d4ff' if current_activation >= 0 else '#ff0080'\n",
    "        \n",
    "        ax_img.text(\n",
    "            0.5, 1.05, f'Sample {frame_idx + 1}/{num_samples}',\n",
    "            transform=ax_img.transAxes,\n",
    "            color='white', fontsize=10, ha='center', va='bottom',\n",
    "            weight='bold'\n",
    "        )\n",
    "        \n",
    "        ax_img.text(\n",
    "            0.5, -0.05, f'{current_activation:.4f} Hz',\n",
    "            transform=ax_img.transAxes,\n",
    "            color=value_color, fontsize=10, ha='center', va='top',\n",
    "            weight='bold',\n",
    "            bbox=dict(\n",
    "                boxstyle='round,pad=0.4',\n",
    "                facecolor='#0a0a0a',\n",
    "                edgecolor=value_color,\n",
    "                linewidth=2\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Curve on right\n",
    "        ax_plot = fig.add_subplot(1, 2, 2)\n",
    "        ax_plot.set_facecolor('#0a0a0a')\n",
    "        \n",
    "        # Plot full curve\n",
    "        ax_plot.plot(sorted_responses, color='#00d4ff', linewidth=2, alpha=0.5, zorder=1)\n",
    "        ax_plot.fill_between(\n",
    "            range(len(sorted_responses)),\n",
    "            sorted_responses,\n",
    "            color='#00d4ff',\n",
    "            alpha=0.2,\n",
    "            zorder=1\n",
    "        )\n",
    "        \n",
    "        # All sampled points (faded)\n",
    "        ax_plot.scatter(\n",
    "            sampled_positions,\n",
    "            sampled_activations,\n",
    "            c='#ff0080',\n",
    "            s=30,\n",
    "            alpha=0.3,\n",
    "            zorder=2\n",
    "        )\n",
    "        \n",
    "        # Visited points (brighter)\n",
    "        if frame_idx > 0:\n",
    "            ax_plot.scatter(\n",
    "                sampled_positions[:frame_idx],\n",
    "                sampled_activations[:frame_idx],\n",
    "                c='#ff0080',\n",
    "                s=50,\n",
    "                alpha=0.6,\n",
    "                zorder=3\n",
    "            )\n",
    "        \n",
    "        # Current point glow\n",
    "        ax_plot.scatter(\n",
    "            current_position,\n",
    "            current_activation,\n",
    "            c=value_color,\n",
    "            s=300,\n",
    "            alpha=0.3,\n",
    "            zorder=4\n",
    "        )\n",
    "        \n",
    "        # Current point\n",
    "        ax_plot.scatter(\n",
    "            current_position,\n",
    "            current_activation,\n",
    "            c=value_color,\n",
    "            s=150,\n",
    "            marker='o',\n",
    "            edgecolors='white',\n",
    "            linewidths=2,\n",
    "            zorder=5\n",
    "        )\n",
    "        \n",
    "        ax_plot.set_xlabel('Sorted Image Index', color='white', fontsize=9, weight='bold')\n",
    "        ax_plot.set_ylabel('Activation (Hz)', color='white', fontsize=9, weight='bold')\n",
    "        ax_plot.tick_params(colors='white', labelsize=8)\n",
    "        \n",
    "        for spine in ax_plot.spines.values():\n",
    "            spine.set_color('#00d4ff')\n",
    "            spine.set_linewidth(2)\n",
    "        \n",
    "        ax_plot.grid(True, alpha=0.2, color='#00d4ff', linestyle='--', linewidth=0.8)\n",
    "        \n",
    "        fig.suptitle(\n",
    "            f'Neuron {neuron_id}',\n",
    "            color='white',\n",
    "            fontsize=12,\n",
    "            weight='bold'\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Convert to array using savefig to buffer\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='raw', dpi=dpi, facecolor='black')\n",
    "        buf.seek(0)\n",
    "        \n",
    "        # Read the buffer\n",
    "        img_array = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "        w, h = fig.canvas.get_width_height()\n",
    "        frame = img_array.reshape((int(h), int(w), -1))[:, :, :3]  # Take only RGB\n",
    "        \n",
    "        frames.append(frame)\n",
    "        buf.close()\n",
    "        plt.close(fig)\n",
    "        \n",
    "        if (frame_idx + 1) % 10 == 0:\n",
    "            print(f\"  Generated {frame_idx + 1}/{num_samples} frames...\")\n",
    "    \n",
    "    print(f\"Writing video to {savename}...\")\n",
    "    # Write video with OpenCV\n",
    "    height, width = frames[0].shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(savename, fourcc, fps, (width, height))\n",
    "    \n",
    "    for frame in frames:\n",
    "        # Convert RGB to BGR for OpenCV\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame_bgr)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Done! Saved to {savename}\")\n",
    "    print(f\"Duration: {num_samples / fps:.1f} seconds at {fps} fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003572af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_images_animation(\n",
    "    neuron_id=4,\n",
    "    dset=dset,\n",
    "    resp_dir=resp_dir,\n",
    "    idx_dir=idx_dir,\n",
    "    num_samples=128,\n",
    "    fps=5,\n",
    "    savename='neuron_4.mp4',\n",
    "    dpi=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04957d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
